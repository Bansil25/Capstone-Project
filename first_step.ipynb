{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import urllib.request\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle as pk\n",
    "from IPython.display import Image, display, clear_output\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import optimizers\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "# get_file has been moved to keras.utils\n",
    "from keras.utils import get_file \n",
    "#from keras.utils.np_utils import to_categorical\n",
    "#from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, Activation, Dropout, Flatten, Dense\n",
    "from keras.callbacks import ModelCheckpoint, History\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "tf.keras.utils.image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_INDEX = None\n",
    "CLASS_INDEX_PATH = 'https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = VGG16(weights='imagenet')\n",
    "vgg19 = VGG19(weights='imagenet')\n",
    "resnet = ResNet50(weights='imagenet')\n",
    "inception = InceptionV3(weights='imagenet')\n",
    "xception = Xception(weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image_224(img_path):\n",
    "    img = load_img(img_path, target_size=(224,224))\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image_299(img_path):\n",
    "    img = load_img(img_path, target_size=(299,299))\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(preds, top=5):\n",
    "    global CLASS_INDEX\n",
    "    if len(preds.shape) != 2 or preds.shape[1] != 1000:\n",
    "        raise ValueError('`decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: ' + str(preds.shape))\n",
    "    if CLASS_INDEX is None:\n",
    "        fpath = get_file('imagenet_class_index.json',CLASS_INDEX_PATH,cache_subdir='models')\n",
    "        CLASS_INDEX = json.load(open(fpath))\n",
    "    results = []\n",
    "    for pred in preds:\n",
    "        top_indices = pred.argsort()[-top:][::-1]\n",
    "        result = [tuple(CLASS_INDEX[str(i)]) + (pred[i],) for i in top_indices]\n",
    "        result.sort(key=lambda x: x[2], reverse=True)\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def prepare_image_224(img_path):\n",
    "    # load_img and img_to_array are now imported from keras.preprocessing.image\n",
    "    img = load_img(img_path, target_size=(224, 224))\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    # Assuming preprocess_input is already imported from the correct module\n",
    "    x = preprocess_input(x)\n",
    "    return x\n",
    "\n",
    "def prepare_image_299(img_path):\n",
    "    # load_img and img_to_array are now imported from keras.preprocessing.image\n",
    "    img = load_img(img_path, target_size=(299, 299))\n",
    "    x = img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    # Assuming preprocess_input is already imported from the correct module\n",
    "    x = preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(r'C:\\Users\\pbans\\OneDrive\\Desktop\\Capstone-Project\\data1a\\training\\00-damage\\0008.JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339ms/step\n",
      "[[('n03670208', 'limousine', 0.5594126), ('n02814533', 'beach_wagon', 0.12945025), ('n02930766', 'cab', 0.06118699), ('n02974003', 'car_wheel', 0.0535922), ('n03770679', 'minivan', 0.04433887)]]\n"
     ]
    }
   ],
   "source": [
    "y = prepare_image_224(r'C:\\Users\\pbans\\OneDrive\\Desktop\\Capstone-Project\\data1a\\training\\00-damage\\0008.JPEG')\n",
    "preds = vgg16.predict(y)\n",
    "print(get_predictions(preds, top=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step\n",
      "[[('n03670208', 'limousine', 0.18979682), ('n02814533', 'beach_wagon', 0.14770667), ('n03459775', 'grille', 0.1316177), ('n03930630', 'pickup', 0.08510228), ('n03770679', 'minivan', 0.07025451)]]\n"
     ]
    }
   ],
   "source": [
    "z = prepare_image_224(r'C:\\Users\\pbans\\OneDrive\\Desktop\\Capstone-Project\\data1a\\training\\00-damage\\0008.JPEG')\n",
    "preds = vgg19.predict(z)\n",
    "print(get_predictions(preds, top=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "[[('n02814533', 'beach_wagon', 0.41607046), ('n03670208', 'limousine', 0.36545718), ('n02974003', 'car_wheel', 0.055521466), ('n02930766', 'cab', 0.03552771), ('n04037443', 'racer', 0.0259703)]]\n"
     ]
    }
   ],
   "source": [
    "a = prepare_image_224(r'C:\\Users\\pbans\\OneDrive\\Desktop\\Capstone-Project\\data1a\\training\\00-damage\\0008.JPEG')\n",
    "preds = resnet.predict(a)\n",
    "print(get_predictions(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "[[('n04328186', 'stopwatch', 0.9999846), ('n06359193', 'web_site', 1.5410998e-05), ('n01924916', 'flatworm', 4.3686642e-14), ('n02841315', 'binoculars', 7.5445664e-16), ('n04355933', 'sunglass', 7.226804e-18)]]\n"
     ]
    }
   ],
   "source": [
    "b = prepare_image_299(r'C:\\Users\\pbans\\OneDrive\\Desktop\\Capstone-Project\\data1a\\training\\00-damage\\0008.JPEG')\n",
    "preds = inception.predict(b)\n",
    "print(get_predictions(preds, top=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002C40E515120> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 718ms/step\n",
      "[[('n03594945', 'jeep', 0.2776874), ('n02099429', 'curly-coated_retriever', 0.12543045), ('n03825788', 'nipple', 0.120987736), ('n03942813', 'ping-pong_ball', 0.11751947), ('n03347037', 'fire_screen', 0.097881176)]]\n"
     ]
    }
   ],
   "source": [
    "c = prepare_image_299(r'C:\\Users\\pbans\\OneDrive\\Desktop\\Capstone-Project\\data1a\\training\\00-damage\\0008.JPEG')\n",
    "preds = xception.predict(c)\n",
    "print(get_predictions(preds, top=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_car_categories():\n",
    "    d = defaultdict(float)\n",
    "    img_list = os.listdir(r'C:\\\\Users\\\\pbans\\\\OneDrive\\\\Desktop\\\\Capstone-Project\\\\data1a\\\\training')\n",
    "    for i, img_path in enumerate(img_list):\n",
    "        img = prepare_image_224(r'C:\\\\Users\\\\pbans\\\\OneDrive\\\\Desktop\\\\Capstone-Project\\\\data1a\\\\training/'+img_path)\n",
    "        out = vgg16.predict(img)\n",
    "        preds = get_predictions(out,top=5)\n",
    "        for pred in preds[0]:\n",
    "            d[pred[0:2]]+=pred[2]\n",
    "        if(i%50==0):\n",
    "            print(i,'/',len(img_list),'complete')\n",
    "    return Counter(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\\\\\Users\\\\\\\\pbans\\\\\\\\OneDrive\\\\\\\\Desktop\\\\\\\\Capstone-Project\\\\\\\\data1a\\\\\\\\training/00-damage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m categ_count \u001b[38;5;241m=\u001b[39m \u001b[43mget_car_categories\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[30], line 5\u001b[0m, in \u001b[0;36mget_car_categories\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m img_list \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mpbans\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCapstone-Project\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdata1a\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, img_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(img_list):\n\u001b[1;32m----> 5\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_image_224\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mpbans\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mOneDrive\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mDesktop\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mCapstone-Project\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mdata1a\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mtraining/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     out \u001b[38;5;241m=\u001b[39m vgg16\u001b[38;5;241m.\u001b[39mpredict(img)\n\u001b[0;32m      7\u001b[0m     preds \u001b[38;5;241m=\u001b[39m get_predictions(out,top\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m, in \u001b[0;36mprepare_image_224\u001b[1;34m(img_path)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprepare_image_224\u001b[39m(img_path):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# load_img and img_to_array are now imported from keras.preprocessing.image\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mload_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     x \u001b[38;5;241m=\u001b[39m img_to_array(img)\n\u001b[0;32m     10\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\pbans\\OneDrive\\Desktop\\CD2\\.conda\\Lib\\site-packages\\keras\\src\\utils\\image_utils.py:235\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, pathlib\u001b[38;5;241m.\u001b[39mPath):\n\u001b[0;32m    234\u001b[0m         path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path\u001b[38;5;241m.\u001b[39mresolve())\n\u001b[1;32m--> 235\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    236\u001b[0m         img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(io\u001b[38;5;241m.\u001b[39mBytesIO(f\u001b[38;5;241m.\u001b[39mread()))\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\\\\\Users\\\\\\\\pbans\\\\\\\\OneDrive\\\\\\\\Desktop\\\\\\\\Capstone-Project\\\\\\\\data1a\\\\\\\\training/00-damage'"
     ]
    }
   ],
   "source": [
    "categ_count = get_car_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\Users\\\\pbans\\\\OneDrive\\\\Desktop\\\\Capstone-Project\\\\data1a\\\\training\\\\00-damage'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mpbans\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mOneDrive\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mDesktop\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mCapstone-Project\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mdata1a\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m00-damage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      2\u001b[0m     content \u001b[38;5;241m=\u001b[39m file\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'C:\\\\Users\\\\pbans\\\\OneDrive\\\\Desktop\\\\Capstone-Project\\\\data1a\\\\training\\\\00-damage'"
     ]
    }
   ],
   "source": [
    "with open('C:\\\\Users\\\\pbans\\\\OneDrive\\\\Desktop\\\\Capstone-Project\\\\data1a\\\\training\\\\00-damage', 'r') as file:\n",
    "    content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
